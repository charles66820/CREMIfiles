{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$x \\mapsto \\text{3.0} + \\text{2.0}\\,x + \\text{1.0}\\,x^{2}$"
      ],
      "text/plain": [
       "Polynomial([3., 2., 1.], domain=[-1,  1], window=[-1,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.polynomial.Polynomial([3, 2, 1])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valeurPolynome(coeff, x):\n",
    "  return np.polynomial.Polynomial(coeff)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valeurPolynome([1, 2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.polyval([1, 2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "985.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valeurPolynome([1, 2, 3, 4], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 57., 209.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V1 = np.array([4, 8])\n",
    "valeurPolynome([1, 2, 3], V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivPoly(coeff):\n",
    "  return np.polyder(coeff[::-1],)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivPoly([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "-0.11754624614399992\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# draw the parabole\n",
    "def parabole(x):\n",
    "  return x * x\n",
    "\n",
    "x = np.linspace(-300,300,600)\n",
    "y = [parabole(i) for i in x]\n",
    "\n",
    "plt.plot(x,y,'g')\n",
    "\n",
    "# desente du gradient\n",
    "epsilon = 0.1\n",
    "nu = 0.2\n",
    "\n",
    "x0=250  # étape 1 x initial\n",
    "xcurrent = x0 - 2*x0 # definition du x courant (étape 2)\n",
    "xprec = x0 # definition du x precedent\n",
    "\n",
    "plt.plot(x0,parabole(x0),'ok') # Draw dot in parabol\n",
    "\n",
    "\n",
    "while(abs(xprec - xcurrent) > epsilon): # étape 3 jusqu'a ce que la valeur et dépasser le minimum\n",
    "  xprec  = xcurrent # definition du x precedent\n",
    "  xcurrent = xprec - nu*2*xprec # definition du x courant avec (étape 2) le calcule de la dérivée différentielle\n",
    "  plt.plot(xcurrent,parabole(xcurrent),'ob') # Draw dot in parabol\n",
    "  plt.pause(0.2) # sleep\n",
    "plt.plot(xcurrent,parabole(xcurrent),'xr') # Draw last dot in parabol\n",
    "print(xcurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. fait\n",
    "2. ça vas plus vite car c'est plus proche. et si la valeur est négative ça vas dans l'autre sense\n",
    "3. On peut avoir une valeur plus précise avec un pa plus petit\n",
    "4. L'algo tourne a l'infini car le nu fait faire la symétrie. Non ce n'est pas spécifique\n",
    "5. dans la version suivant on augmente l'attenuation ce qui fait que le mu commence vers 0.9 et est de plus en plus base donc pressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f317a051910>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parabole(x):\n",
    "    return x * x\n",
    "\n",
    "x = np.linspace(-300,300,600)\n",
    "y = [parabole(i) for i in x]\n",
    "\n",
    "epsilon = 0.1\n",
    "attenuation = 3\n",
    "\n",
    "plt.plot(x,y,'g')\n",
    "\n",
    "x0=250\n",
    "xcurrent = x0 - 2*x0\n",
    "xprec = x0\n",
    "\n",
    "plt.plot(x0,parabole(x0),'ok')\n",
    "\n",
    "while(abs(xprec - xcurrent) > epsilon):\n",
    "    xprec  = xcurrent\n",
    "    nu = 1/np.log(attenuation)\n",
    "    attenuation = attenuation+1\n",
    "    xcurrent = xprec - nu*2*xprec\n",
    "    plt.plot(xcurrent,parabole(xcurrent),'ob')\n",
    "    plt.pause(0.2)\n",
    "plt.plot(xcurrent,parabole(xcurrent),'xr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. La variable nu dmininue et l'intérêt de procéder ainsi est d'être plus précis et d'éviter une boucle infinie.\n",
    "7. Si la valeur initial est a 0 cela ne fonctionne pas car il n'y as pas d'atenuation. L'ateunation est plus forte si on l'aubmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$x \\mapsto \\text{30.0} - \\text{61.0}\\,x + \\text{41.0}\\,x^{2} - \\text{11.0}\\,x^{3} + \\text{1.0}\\,x^{4}$"
      ],
      "text/plain": [
       "Polynomial([ 30., -61.,  41., -11.,   1.], domain=[-1,  1], window=[-1,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.polynomial.Polynomial([30, -61, 41, -11, 1])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "1.335146328676731\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# draw the polynom\n",
    "x = np.linspace(0,6, 60)\n",
    "coefpoly = np.array([30, -61, 41, -11, 1])\n",
    "\n",
    "y = [p(i) for i in x]\n",
    "derive = derivPoly(coefpoly)\n",
    "plt.plot(x, y,'g')\n",
    "\n",
    "# desente du gradient\n",
    "epsilon = 0.01\n",
    "mu = 0.01\n",
    "\n",
    "x0 = 0\n",
    "xprec = x0\n",
    "xcurrent = xprec - mu*valeurPolynome(derive, xprec)\n",
    "\n",
    "plt.plot(xprec, p(xprec),'ok')\n",
    "while(abs(xprec - xcurrent) > epsilon):\n",
    "  plt.plot(xprec, p(xprec),'ob')\n",
    "  xprec  = xcurrent\n",
    "  xcurrent = xprec - mu*valeurPolynome(derive, xprec)\n",
    "  plt.pause(0.2)\n",
    "plt.plot(xcurrent, p(xcurrent),'xr')\n",
    "print(xcurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La décente de gradient ce fait sur la partie la plus basse a gauche et ne vas pas a l'endroit le plus bas\n",
    "2. c'est la même logique qu'avec la parabole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35586/2965477440.py:12: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  ax = Axes3D(plt.figure())\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def f(x,y):\n",
    "    return (x - 1) * (x - 2) + (y + 3) * (y + 4)\n",
    "\n",
    "x = np.linspace(-8, 8, 160)\n",
    "y = np.linspace(-8, 8, 160)\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = f(x, y)\n",
    "\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "ax.plot_surface(x, y, z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientSurfaceTest(x, y):\n",
    "  return 2 * x - 3, 2 * y + 7 +10\n",
    "\n",
    "def animationDescenteSurface(x, y, pdep):\n",
    "  plt.figure()\n",
    "  plt.contour(x, y, f(x,y))\n",
    "  xprec = pdep[0]\n",
    "  yprec = pdep[1]\n",
    "\n",
    "  epsilon = 0.1\n",
    "\n",
    "  nu = 0.05\n",
    "\n",
    "  dx,dy = gradientSurfaceTest(xprec, yprec)\n",
    "\n",
    "  dist = np.linalg.norm([dx,dy])\n",
    "  xcurrent = xprec - nu*dx\n",
    "  ycurrent = yprec - nu*dy\n",
    "\n",
    "  while(dist > epsilon):\n",
    "    try:\n",
    "      with np.errstate(all='raise'):\n",
    "        plt.scatter(xcurrent, ycurrent, f(xcurrent, ycurrent))\n",
    "    except FloatingPointError:\n",
    "      pass\n",
    "    xprec = xcurrent\n",
    "    yprec = ycurrent\n",
    "\n",
    "    dx,dy = gradientSurfaceTest(xprec,yprec)\n",
    "\n",
    "    dist = np.linalg.norm([dx,dy])\n",
    "\n",
    "    xcurrent = xprec-nu*dx\n",
    "    ycurrent = yprec-nu*dy\n",
    "\n",
    "    plt.pause(0.2);\n",
    "  plt.scatter(xcurrent, ycurrent, f(xcurrent, ycurrent))\n",
    "  print(xcurrent)\n",
    "  print(ycurrent)\n",
    "\n",
    "x = np.linspace(-8, 8, 160)\n",
    "y = np.linspace(-8, 8, 160)\n",
    "x, y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4979127210410355\n",
      "-8.45616714186174\n"
     ]
    }
   ],
   "source": [
    "animationDescenteSurface(x,y,(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.494013742408719\n",
      "-8.458096196861032\n"
     ]
    }
   ],
   "source": [
    "animationDescenteSurface(x,y,(1,-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4823258737746225\n",
      "-8.46111692230417\n"
     ]
    }
   ],
   "source": [
    "animationDescenteSurface(x,y,(-1,-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.475755656755312\n",
      "-8.466057919457436\n"
     ]
    }
   ],
   "source": [
    "animationDescenteSurface(x,y,(-1,-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5048488686489376\n",
      "-8.45636018215956\n"
     ]
    }
   ],
   "source": [
    "animationDescenteSurface(x,y,(2,-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{1}{m}\\sum(\\theta_0+\\theta_1x_i-y_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientJ (theta, x, y):\n",
    "  theta0 = theta[0]\n",
    "  theta1 = theta[1]\n",
    "  t0 = [theta0 + theta1 * x[i] - y[i] for i in range(len(x))]\n",
    "  t1 = [x[i] * (theta0 + theta1 * x[i] - y[i]) for i in range(len(x))]\n",
    "\n",
    "  dtheta0 = np.sum(t0)#theta0 + theta1 * x - y)\n",
    "  dtheta1 = np.sum(t1)#x * (theta0 + theta1*x - y))\n",
    "\n",
    "  m = len(x)\n",
    "  dtheta0 = 2*dtheta0 / m\n",
    "  dtheta1 = 2*dtheta1 / m\n",
    "  return dtheta0, dtheta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23.061875828527434, 0.8609029709082938)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3178a218e0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "from random import random\n",
    "m = 40\n",
    "sizeNoise = 10\n",
    "x = [random()*50 + 5 for i in range(m)]\n",
    "noise = [random() * sizeNoise for i in range(m)] # ou np.rand(m,1) * sizeNoise\n",
    "pente = 0.8\n",
    "b =  20\n",
    "y = [b + pente*x[i] + noise[i] for i in range(m)]\n",
    "\n",
    "plt.plot(x,y,'bx')\n",
    "\n",
    "# linear regresssion\n",
    "theta = (10, 1)\n",
    "epsilon = 0.1\n",
    "nu = 0.0005\n",
    "\n",
    "dtheta0, dtheta1 = gradientJ (theta, x, y)\n",
    "\n",
    "dist = np.linalg.norm([dtheta0,dtheta1])\n",
    "\n",
    "while(dist > epsilon):\n",
    "  theta = theta[0] - nu * dtheta0, theta[1] - nu * dtheta1\n",
    "  dtheta0, dtheta1 = gradientJ (theta, x, y)\n",
    "  dist = np.linalg.norm([dtheta0,dtheta1])\n",
    "\n",
    "print(theta)\n",
    "\n",
    "xd = [0, 60]\n",
    "yd = [theta[0], 60*theta[1]+ theta[0]]\n",
    "plt.plot(xd , yd, 'r')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
