{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "from numpy.linalg import eig, inv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes :\n",
    "|nb|name|\n",
    "|--|--|\n",
    "|0 |T-shirt/top|\n",
    "|1 |Trouser|\n",
    "|2 |Pullover|\n",
    "|3 |Dress|\n",
    "|4 |Coat|\n",
    "|5 |Sandal|\n",
    "|6 |Shirt|\n",
    "|7 |Sneaker|\n",
    "|8 |Bag|\n",
    "|9 |Ankle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}\n",
    "def isA(nb: int):\n",
    "  return classes[nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "plt.imshow(X_train[0], cmap=cm.Greys)\n",
    "print(\"Class:\", isA(Y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que l'element 0 est de la class `Ankle boot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test des differents algorithmes de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re shape\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def executeKnn(X_train, Y_train, X_test, Y_test, k=5):\n",
    "  # Create K-nn classifier\n",
    "  knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "  t = time()\n",
    "  # Train the classifier\n",
    "  knn.fit(X_train, Y_train)\n",
    "  print(\"training time: \", time() - t)\n",
    "\n",
    "  # Test the classifier\n",
    "  Y_pred = knn.predict(X_test)\n",
    "\n",
    "  print(\"k = {:d} : {:.2%}\".format(k, accuracy_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se limite à un échantillon du dataset car le K-nn était trop lent à s'exécuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb train 60000\n",
      "Nb test 10000\n",
      "Nb train sample 7500\n",
      "Nb test sample 1250\n"
     ]
    }
   ],
   "source": [
    "nbTrain = X_train.shape[0]\n",
    "print(\"Nb train\", nbTrain)\n",
    "nbTest = X_test.shape[0]\n",
    "print(\"Nb test\", nbTest)\n",
    "\n",
    "divFactor = 8\n",
    "\n",
    "nbTrainSample = round(nbTrain / divFactor)\n",
    "print(\"Nb train sample\", nbTrainSample)\n",
    "nbTestSample = round(nbTest / divFactor)\n",
    "print(\"Nb test sample\", nbTestSample)\n",
    "\n",
    "X_train_sample = X_train[:nbTrainSample]\n",
    "Y_train_sample = Y_train[:nbTrainSample]\n",
    "X_test_sample = X_test[:nbTestSample]\n",
    "Y_test_sample = Y_test[:nbTestSample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.544898509979248\n",
      "k = 1 : 79.28%\n",
      "training time:  0.5133836269378662\n",
      "k = 2 : 80.64%\n",
      "training time:  0.5168232917785645\n",
      "k = 3 : 80.80%\n",
      "training time:  0.5087499618530273\n",
      "k = 4 : 80.88%\n",
      "training time:  0.49982404708862305\n",
      "k = 5 : 82.24%\n"
     ]
    }
   ],
   "source": [
    "for k in range (1, 6):\n",
    "  executeKnn(X_train_sample, Y_train_sample, X_test_sample, Y_test_sample, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieur bayésien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def executeBayes(X_train, Y_train, X_test, Y_test):\n",
    "  # Create ML classifier\n",
    "  knn = GaussianNB()\n",
    "  t = time()\n",
    "  # Train the classifier\n",
    "  knn.fit(X_train, Y_train)\n",
    "  print(\"training time: \", time() - t)\n",
    "\n",
    "  # Test the classifier\n",
    "  Y_pred = knn.predict(X_test)\n",
    "\n",
    "  print(\"{:.2%}\".format(accuracy_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.5331282615661621\n",
      "58.56%\n"
     ]
    }
   ],
   "source": [
    "executeBayes(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "\n",
    "def displayTree(dt, features_cols, class_names):\n",
    "  dot_data = StringIO()\n",
    "  export_graphviz(dt, out_file=dot_data,\n",
    "                  filled=True, rounded=True,\n",
    "                  special_characters=True,feature_names = features_cols,class_names=class_names)\n",
    "  graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "  graph.write_png('fashion.png')\n",
    "  Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def executeDecisionTree(X_train, Y_train, X_test, Y_test, display=False):\n",
    "  # Create Decision Tree classifier\n",
    "  dt = DecisionTreeClassifier(criterion='entropy')\n",
    "  t = time()\n",
    "  # Train the classifier\n",
    "  dt.fit(X_train, Y_train)\n",
    "  print(\"training time: \", time() - t)\n",
    "\n",
    "  if display:\n",
    "    features_cols = [str(k) for k in range(X_train.shape[1])]\n",
    "    class_names = [str(k) for k in classes.keys()]\n",
    "    displayTree(dt, features_cols, class_names)\n",
    "\n",
    "  # Test the classifier\n",
    "  Y_pred = dt.predict(X_test)\n",
    "\n",
    "  print(\"{:.2%}\".format(accuracy_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  32.81132435798645\n",
      "80.32%\n"
     ]
    }
   ],
   "source": [
    "executeDecisionTree(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a trop de données donc l'arbre de décision est trop grand pour être affiché"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  81.17%\n",
      "Parameters:  ['entropy', 10, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "min_samples_split = [2, 3, 4]\n",
    "\n",
    "best_params = None\n",
    "best_score = 0\n",
    "for c in criterion:\n",
    "    for depth in max_depth:\n",
    "        for l in min_samples_leaf:\n",
    "            for s in min_samples_split:\n",
    "                dt = DecisionTreeClassifier(criterion=c, max_depth=depth, min_samples_leaf=l, min_samples_split=s)\n",
    "                dt.fit(X_train, Y_train)\n",
    "                y_pred = dt.predict(X_test)\n",
    "                scores = accuracy_score(Y_test, y_pred)\n",
    "                if best_score==0 or scores > best_score:\n",
    "                    best_score = scores\n",
    "                    best_params = [c, depth, l, s]\n",
    "\n",
    "print('Best Accuracy: ','{:2.2%}'.format(best_score))\n",
    "print('Parameters: ', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def executeRandomForest(X_train, Y_train, X_test, Y_test):\n",
    "  # Create Random Forest classifier\n",
    "  rf = RandomForestClassifier()\n",
    "  t = time()\n",
    "  # Train the classifier\n",
    "  rf.fit(X_train, Y_train)\n",
    "  print(\"training time: \", time() - t)\n",
    "\n",
    "  # Test the classifier\n",
    "  Y_pred = dt.predict(X_test)\n",
    "\n",
    "  print(\"{:.2%}\".format(accuracy_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  84.11152672767639\n",
      "81.08%\n"
     ]
    }
   ],
   "source": [
    "executeRandomForest(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [3, 5, 10, None], 'min_samples_split': [1, 2, 5], 'min_samples_leaf': [2, 3, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [3, 5, 10]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1, 2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 3, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  rf = RandomForestClassifier()\n",
    "  rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100,\n",
    "                                cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "  t = time()\n",
    "\n",
    "  rf_random.fit(X_train, Y_train)\n",
    "  print(\"training time: \", time() - t)\n",
    "\n",
    "  Y_pred = dt.predict(X_test)\n",
    "  print(\"{:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "  rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vois que TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparaison des technique de reduction de dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
