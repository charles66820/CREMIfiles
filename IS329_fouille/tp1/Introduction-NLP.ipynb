{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wordcloud\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "![South Park](https://upload.wikimedia.org/wikipedia/en/4/41/South_Park_main_characters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de données récupéré sur kaggle : https://www.kaggle.com/tovarischsukhov/southparklines\n",
    "df = pd.read_csv(\"southpark.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorons le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Si vous ne connaissez pas pandas c'est le moment de prendre 10min pour vous former : https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "\n",
    "----\n",
    "Cartman parle beaucoup il occupe la parole x% du temps : quel est cette proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cartman         9774\n",
       "Stan            7680\n",
       "Kyle            7099\n",
       "Butters         2602\n",
       "Randy           2467\n",
       "Mr. Garrison    1002\n",
       "Chef             917\n",
       "Kenny            881\n",
       "Sharon           862\n",
       "Mr. Mackey       633\n",
       "Name: Character, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quels sont les personnages les plus présents ?\n",
    "df[\"Character\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "      <td>70896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3950</td>\n",
       "      <td>64301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Cartman</td>\n",
       "      <td>What?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6416</td>\n",
       "      <td>5271</td>\n",
       "      <td>9774</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season Episode Character     Line\n",
       "count   70896   70896     70896    70896\n",
       "unique     19      19      3950    64301\n",
       "top         2      10   Cartman  What?\\n\n",
       "freq     6416    5271      9774      361"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartman or Not Cartman\n",
    "\n",
    "![South Park](https://cdn.radiofrance.fr/s3/cruiser-production/2019/09/31a9cba2-d57f-4172-9ff1-93a0fe505e75/801x410_eric_cartman_south_park.jpg)\n",
    "\n",
    "On voit que Cartman est le personnage le plus présent dans le dataset, il prend la paole 14% du temps.\n",
    "\n",
    "On va préparer le jeu de données pour résoudre le problème suivant :\n",
    "Pour chaque phrase du jeu de donnée on veut vouloir prédire si elle a été prononcée par Cartman ou par quelqu'un d'autre\n",
    "\n",
    "Pour commencer on va ajouter la colonne \"is_cartman\" au dataframe df : elle doit être à 1 si c'est cartman qui a prononcé la phrase, 0 si ce n'est pas lui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va équilibrer le problème, on veut conserver autant de is_cartman à 0 qu'à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cartman = len(df.query(\"is_cartman == 1\"))\n",
    "nb_cartman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe ça doit être bon\n",
    "assert len(df.query(\"is_cartman == 1\")) == len(df.query(\"is_cartman == 0\"))\n",
    "assert len(df.query(\"is_cartman == 1\")) == nb_cartman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservons uniquement les colonnes qui vont nous intéresser : Line et is_cartman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe ça doit être bon\n",
    "assert (df.columns == [\"Line\", \"is_cartman\"]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va splitter aléatoirement le dataframe en 2, un dataframe pour l'entrainement du modèle et un autre pour la validation.\n",
    "\n",
    "On veut 50% des données pour l'entrainement et 50% pour la validation et on les appelle df_train et df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train) == len(df_valid), \"train et valid n'ont pas la même taille\"\n",
    "assert len(df_train) == len(df) / 2, \"df doit être 2x plus grand que train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va oublier un temps df_valid et se concentrer uniquement à la préparation des données sur df_train\n",
    "\n",
    "# Text preprocessing\n",
    "\n",
    "faites une fonction extract_tokens qui pour extraire les tokens d'un texte :\n",
    "    - nltk est l'outil parfait pour vous aider (https://www.nltk.org/)\n",
    "    - les textes sont en anglais, veuillez à bien utiliser les fonctions en english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sample text. Use it to test your function!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe c'est bon\n",
    "assert (extract_tokens(text) == [\"This\", \"is\", \"a\", \"sample\", \"text\", \".\", \"Use\", \"it\", \"to\", \"test\", \"your\", \"function\", \"!\"]), \"nope\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyez le texte en créant la fonction clean_tokens: supprimez la ponctuation et mettez tout en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe c'est bon\n",
    "assert (clean_tokens(extract_tokens(text)) == [\"this\", \"is\", \"a\", \"sample\", \"text\", \"use\", \"it\", \"to\", \"test\", \"your\", \"function\"]), \"nope\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez la colonne tokens à votre dataframe d'entrainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe ça doit être bon\n",
    "assert (df_train.columns == [\"Line\", \"is_cartman\", \"tokens\"]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisons les mots\n",
    "\n",
    "On va générer des wordcloud représentant la fréquence des mots dans notre dataset\n",
    "\n",
    "On va pour cela compter tous les mots puis les afficher avec le package wordcloud : http://amueller.github.io/word_cloud/\n",
    "\n",
    "Comptons tous les mots et créons le dictionnaire word_freq = {\"mot\": nb_occurence_mot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on peut utiliser maintenant utiliser : http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html#wordcloud.WordCloud.generate_from_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = wordcloud.WordCloud(width=800, height=600).generate_from_frequencies(word_freq)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduisez la même chose sur les sous ensembles is_cartman == 0 et is_cartman == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est-ce que vous observez?\n",
    "Qu'a t'on oublié?\n",
    "Appliquez le correctif sur les données et affichez à nouveau les wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words\n",
    "\n",
    "Le texte est maintenant nettoyé, on va le transformer en features en prenant le modèle basique du \"bag of words\".\n",
    "\n",
    "Vous allez construire tout d'abord le dictionnaire complet des mots du corpus, et associer à chaque mot un id entre 0 et nb_words.\n",
    "Cet id correspondra à la position du mot dans le vecteur des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_id = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque réplique vous allez compter le nombre d'occurences de chaque mot et générer le vecteur des features en utilisant le dictionnaire que vous venez de générer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_to_vector(bag_of_words, words_to_id):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générez la matrice X_train qui pour chaque ligne contient les features.\n",
    "\n",
    "Ca doit être un np.array de taille (len(df_train), len(words_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(X_train) == np.ndarray, \"X_train doit être un np.array\"\n",
    "assert X_train.shape == (len(df_train), len(words_to_id)), \"Mauvaise taille\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prépare le vecteur à prédire\n",
    "y_train = df_train[\"is_cartman\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un peu de Machine learning\n",
    "\n",
    "On va maintenant utiliser scikit learn pour apprendre une régression logistique sur nos données d'entrainement : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "Etape 1 : Créez le modèle\n",
    "Etape 2 : fit(X, y)\n",
    "Etape 3 : Evaluons les performances\n",
    "\n",
    "Commencez par instancier le modèle et lancez l'apprentissage sur l'ensemble de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la matrice de confusion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracez la courbe roc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si je vous demande d'appliquer votre modèle sur des données que vous n'avez jamais vu, quelles seront les performances de vos prédictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Du machine learning avec un peu de maitrise\n",
    " - On n'évalue pas les performances d'un modèle sur les données d'entrainement, c'est facile de prédire ce que l'on connait -> Vous vous souvenez du df_valid ?\n",
    " - Un outil bien utile pour quantifier les performances d'un modèle de ML : la validation croisée\n",
    " \n",
    "Commencez par appliquer toutes les transformations que vous avez appliqué à df_train pour générer X_train afin de passer de df_valid à X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluez les performances de votre modèle en utilisant X_valid et y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca donne quoi par rapport aux performances observées sur les données d'entrainement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez une validation croisée sur votre modèle: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "Utilisez du k-fold avec k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la validation croisée vous pouvez vérifier que votre modèle a des performances uniformes sur l'ensemble de vos données d'entrainement.\n",
    "Vous pouvez estimer l'incertitude de vos futures prédictions grace aux variations de performances que vous observez sur les cross validations.\n",
    "https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "\n",
    "Sur des modèles plus complexes qui possèdent des hyperparamètres, vous pouvez utiliser une cross validation pour apprendre les hyperparametres les plus adaptés à votre problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorons le modèle en affinant les features\n",
    " - Est-ce que utiliser de la stemmatisation améliore les choses?\n",
    " - On a supprimé la ponctuation, est-ce que la remettre améliore le modèle?\n",
    " - On a aussi parlé du tf-idf\n",
    "nltk peut être d'une grande aide pour les 2 1ers points\n",
    "\n",
    "Essayez un stemmer par exemple : https://kite.com/python/docs/nltk.SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez X_train_st et X_valid_st puis mesurez les effets de ces nouvelles features sur le modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réintégrez la ponctuation dans votre modèle.\n",
    "Par exemple rajoutez 2 colonnes à vos features pour y mettre une indicatrice sur la présence de \"!\" et une autre sur la présence de \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment évoluent les performances de votre modèle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au tour du TF-IDF : vous pouvez utiliser https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer\n",
    "\n",
    "Ou le coder vous même, la formule est ici : https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez X_train_tfidf et X_valid_tfidf puis mesurez les effets de ces nouvelle features sur le modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorons le modèle en utilisant un autre classifier :\n",
    "Essayez un autre classifier, au choix https://scikit-learn.org/stable/supervised_learning.html#supervised-learning et comparez les performances vs la régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains classifiers ont des hyperparamètres. Il faut identifier quels sont les hyperparametres les plus pertinents pour notre problème.\n",
    "\n",
    "Une des possibilités est d'utiliser un algorithme de grid search : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour aller plus loin :\n",
    " - Refaites l'exercice sans équilibrer les classes\n",
    " - Refaites l'exercice avec un autre des top personnages\n",
    " - Faites de la classification multi-classe avec le top 5 des personnages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
