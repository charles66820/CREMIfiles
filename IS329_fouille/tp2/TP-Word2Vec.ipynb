{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import gensim\n",
    "import spacy\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "![Analyse de sentiments](https://modernmarketing.co.za/wp-content/uploads/2019/10/Developing-Customer-Centric-Strategy-Through-Automation-1-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset critiques IMDB\n",
    "df_train = pd.read_csv(\"train.csv.gz\")\n",
    "df_valid = pd.read_csv(\"test.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorez les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      4\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      1\n",
       "2  If only to avoid making this type of film in t...      1\n",
       "3  This film was probably inspired by Godard's Ma...      2\n",
       "4  Oh, brother...after hearing about this ridicul...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  I love sci-fi and am willing to put up with a ...      3\n",
       "1  Worth the entertainment value of a rental, esp...      4\n",
       "2  its a totally average film with a few semi-alr...      3\n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      2\n",
       "4  First off let me say, If you haven't enjoyed a...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du jeu de données\n",
    "\n",
    "On a des critiques qui ont un score entre 1 et 10.\n",
    "\n",
    "On va dire qu'une critique est positive si le score est plus grand que 5 et négative sinon.\n",
    "\n",
    "Créez la colonne \"positive\" qui contient 0 pour les critiques négatives et 1 pour les positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe c'est ok\n",
    "nb_positives = (df_train[\"positive\"] == 1).sum()\n",
    "assert nb_positives == 12500, f\"nb_positives = {nb_positives} au lieu de 12500\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words preprocessing\n",
    "\n",
    "On récupère toutes les fonctions de preprocessing pour convertir les textes en matrice de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nécessaire la 1ere fois\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def extract_tokens(text):\n",
    "    res = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        res += nltk.word_tokenize(sent)\n",
    "    return res\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    return [token.lower() for token in tokens if token not in string.punctuation]\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if token not in STOP_WORDS]\n",
    "\n",
    "def text2tokens(text):\n",
    "    tokens = extract_tokens(text)\n",
    "    tokens = clean_tokens(tokens)\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn a toutes les fonctionalités dont on a besoin : https://scikit-learn.org/stable/modules/classes.html?highlight=text#module-sklearn.feature_extraction.text\n",
    "\n",
    "Utilisez ces nouveaux outils pour générer les matrices X_train et X_valid à partir de df_train[\"text\"] et df_valid[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectoriser = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la taille du vocabulaire utilisé par votre vectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prépare le vecteur à prédire\n",
    "y_train = # \n",
    "y_valid = # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un peu de Machine learning\n",
    "\n",
    "On va maintenant utiliser scikit learn pour apprendre une régression logistique sur nos données d'entrainement : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "Etape 1 : Créez le modèle\n",
    "\n",
    "Etape 2 : fit(X, y)\n",
    "\n",
    "Etape 3 : Evaluons les performances\n",
    "\n",
    "Commencez par instancier le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancez l'apprentissage sur l'ensemble de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichez la matrice de confusion\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "Explorez les options 'normalize' : Quelle information est la plus pertinente ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracez la courbe ROC\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html?highlight=roc%20curve#sklearn.metrics.plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer l'AUC : Area Under the ROC Curve\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html?highlight=auc#sklearn.metrics.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Au tour de Word2Vec\n",
    "\n",
    "Commencez par rajouter la colonne tokens aux dataframes df_train et df_valid.\n",
    "Vous allez y stocker les tokens des textes en utilisant les fonctions données en début du notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ça passe c'est ok\n",
    "assert \"tokens\" in df_train.columns, df_train.columns\n",
    "assert \"tokens\" in df_valid.columns, df_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser gensim et sa fonction Word2Vec : https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "Crééz un modèle appelé w2v :\n",
    " - Choisissez des vecteur de taille 300,\n",
    " - entrainez le modèle sur les tokens d'entrainement (df_train)\n",
    " - pensez à utiliser tous les cpus à votre disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que king - man + woman nous donne queen ? Oui/Non et surtout pourquoi?\n",
    "\n",
    "indice : utilisez la méthode most_similar du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorez un peu le modèle, est-ce que vous trouvez des choses intéressantes?\n",
    "\n",
    "La méthode doesnt_match peut être intéressante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning avec word2vec\n",
    "\n",
    "Grace au modèle word2vec on est capable de transformer un mot en vecteur et ces vecteurs ont des propriétés intéressantes.\n",
    "\n",
    "Mais on travaille avec des textes composés de plusieurs mots et de plusieurs phrases. Comment utiliser le modèle sur un texte complet.\n",
    "\n",
    "La possibilité la plus souvent utilisée est de prendre la moyenne des vecteurs associés aux mots du texte. Voyons voir ce que ça donne comme performance vs le TF-IDF du début du TP.\n",
    "\n",
    "Créez la fonction text2vec qui à un texte retourne le vecteur qui correspond à la moyenne des vecteurs associés aux mots du texte. (regardez la méthode mean des array numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez la matrice d'entrainement X_train_w2v à partir de df_train et de text2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez la matrice de validation X_valid_w2v à partir de df_valid et de text2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine une régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On plot la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On plot la courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule l'AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors Word2Vec ça résoud tout les problèmes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Et si on charge le word2vec de google\n",
    "\n",
    "Il est dispo sur miriel045 : /tmp/jacq/GoogleNews-vectors-negative300.bin.gz\n",
    "Copiez le sur le /tmp de votre machine, pas dans votre home! (1.5G)\n",
    "\n",
    "Vous pouvez aussi utiliser [spacy](https://spacy.io/usage/models) en chargeant les modèles : en_core_web_md ou en_core_web_lg\n",
    "\n",
    "Est-ce que le modèle obtenu avec ces vecteurs est plus performant que le notre? Que le TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
