{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TP4bis : Deep Learning appliqué aux images\n",
    "\n",
    "## Les images\n",
    " - Les couches utilisées par les méthodes Deep Learning sur les images : Vocabulaire + concepts\n",
    " - Application : Implémenter le réseau LeNet-5\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*ueA-rooOaiIo3s2rVVz3Ww.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les layers pour les images\n",
    "\n",
    "## Les convolutions\n",
    "-> Leur but : Extraire des features locales des images\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "\n",
    "=> https://github.com/vdumoulin/conv_arithmetic\n",
    "\n",
    "\n",
    "## Les poolings\n",
    "-> leur but : Diminuer la taille de l'output\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
    "\n",
    "\n",
    "## Les DropOuts\n",
    "-> Leur but : Diminuer le sur-apprentissage (overfitting)\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout\n",
    "\n",
    "\n",
    "## Les fonctions d'activation\n",
    "-> Leur but : Introduire des non linéarités\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémenter le réseau LeNet-5\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*ueA-rooOaiIo3s2rVVz3Ww.png)\n",
    "\n",
    "Les clefs pour décoder ce schéma :\n",
    "- Cx — convolution layer,\n",
    "- Sx — subsampling (pooling) layer,\n",
    "- Fx — fully-connected layer, (La Linear de la dernière fois)\n",
    "- x — index of the layer.\n",
    "\n",
    "-> le petit détail en + il y a une fonction d'activation après chaque convolution et chaque layer linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentez le réseau LeNet5 en pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize((\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)),\n\u001b[1;32m     16\u001b[0m                                 transforms\u001b[39m.\u001b[39mToTensor()])\n\u001b[1;32m     18\u001b[0m \u001b[39m# download and create datasets\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m                                train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     21\u001b[0m                                transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m     23\u001b[0m valid_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mMNIST(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m                                train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m                                transform\u001b[39m=\u001b[39mtransform)\n\u001b[1;32m     27\u001b[0m \u001b[39m# define the data loaders\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:102\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_data()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from IPython.display import display\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# download and create datasets\n",
    "train_dataset = datasets.MNIST(root='',\n",
    "                               train=True,\n",
    "                               transform=transform)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='',\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "# define the data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers to train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A vous de jouer\n",
    "\n",
    "Assemblez les éléments pour entrainer le modèle, évaluer ses performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "test(model, device, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, classe = random.choice(train_loader.dataset)\n",
    "print(classe)\n",
    "display(transforms.ToPILImage()(img))\n",
    "predict(model, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
